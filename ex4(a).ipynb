{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70a2add-6d49-4481-b7ef-be0271fcc212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Installing required libraries...\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Install Libraries\n",
    "print(\"STEP 1: Installing required libraries...\")\n",
    "!pip install nltk scikit-learn pandas --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f1b480-0b45-4d9f-87c5-33ea7352220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Importing libraries...\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Import Libraries\n",
    "print(\"STEP 2: Importing libraries...\")\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7aea1ab-6a28-4d40-9137-e45e703ea56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: Downloading punkt and stopwords...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tcs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tcs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 3: Download NLTK Resources\n",
    "print(\"STEP 3: Downloading punkt and stopwords...\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba0a4552-acb7-43f7-be88-3fda99543163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4a: Selected column 'Text'\n",
      "0    Absolutely wonderful - silky and sexy and comf...\n",
      "1                   Love this dress! it's sooo pretty.\n",
      "2     I had to return it - the fit was just not right.\n",
      "3                  Terrible quality. Do not recommend.\n",
      "4    Fast shipping and good packaging, but the prod...\n",
      "Name: Text, dtype: object\n",
      "\n",
      "4b: Removing missing/null values\n",
      "\n",
      "4c: Keeping top 10,000 reviews (if present)\n",
      "                                                Text\n",
      "0  Absolutely wonderful - silky and sexy and comf...\n",
      "1                 Love this dress! it's sooo pretty.\n",
      "2   I had to return it - the fit was just not right.\n",
      "3                Terrible quality. Do not recommend.\n",
      "4  Fast shipping and good packaging, but the prod...\n",
      "5  The color is not the same as shown in the pict...\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Load Dataset\n",
    "\n",
    "data = {\n",
    "    'Text': [\n",
    "        \"Absolutely wonderful - silky and sexy and comfortable.\",\n",
    "        \"Love this dress! it's sooo pretty.\",\n",
    "        \"I had to return it - the fit was just not right.\",\n",
    "        \"Terrible quality. Do not recommend.\",\n",
    "        \"Fast shipping and good packaging, but the product is bad.\",\n",
    "        \"The color is not the same as shown in the picture.\"\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 4a: Select 'Text' column\n",
    "print(\"\\n4a: Selected column 'Text'\")\n",
    "print(df['Text'].head())\n",
    "\n",
    "# 4b: Remove nulls\n",
    "print(\"\\n4b: Removing missing/null values\")\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "# 4c: Keep first 10,000 records\n",
    "print(\"\\n4c: Keeping top 10,000 reviews (if present)\")\n",
    "df = df.head(10000)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00cde7a5-75d6-48a6-8587-e64ba2db5d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5a: Number of stopwords loaded: 198\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Load Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(\"5a: Number of stopwords loaded:\", len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12e42d35-a16b-4658-902e-208f9d6d6cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tcs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt', quiet=False) \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc69ae5f-9b3d-4cda-8ad0-c2c6642a2dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: This dress is really pretty!\n",
      "Lower: this dress is really pretty!\n",
      "No punctuation: this dress is really pretty\n",
      "Tokenized: ['this', 'dress', 'is', 'really', 'pretty']\n",
      "No stopwords: ['dress', 'really', 'pretty']\n",
      "dress really pretty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tcs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tcs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    print(\"Original:\", text)\n",
    "    text = text.lower()\n",
    "    print(\"Lower:\", text)\n",
    "    text = ''.join([c for c in text if c.isalnum() or c.isspace()])\n",
    "    print(\"No punctuation:\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    print(\"Tokenized:\", tokens)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    print(\"No stopwords:\", tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "print(preprocess_text(\"This dress is really pretty!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0686d64-3b86-4fd5-844f-d14923c7a4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Absolutely wonderful - silky and sexy and comfortable.\n",
      "Lower: absolutely wonderful - silky and sexy and comfortable.\n",
      "No punctuation: absolutely wonderful  silky and sexy and comfortable\n",
      "Tokenized: ['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable']\n",
      "No stopwords: ['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable']\n",
      "Original: Love this dress! it's sooo pretty.\n",
      "Lower: love this dress! it's sooo pretty.\n",
      "No punctuation: love this dress its sooo pretty\n",
      "Tokenized: ['love', 'this', 'dress', 'its', 'sooo', 'pretty']\n",
      "No stopwords: ['love', 'dress', 'sooo', 'pretty']\n",
      "Original: I had to return it - the fit was just not right.\n",
      "Lower: i had to return it - the fit was just not right.\n",
      "No punctuation: i had to return it  the fit was just not right\n",
      "Tokenized: ['i', 'had', 'to', 'return', 'it', 'the', 'fit', 'was', 'just', 'not', 'right']\n",
      "No stopwords: ['return', 'fit', 'right']\n",
      "Original: Terrible quality. Do not recommend.\n",
      "Lower: terrible quality. do not recommend.\n",
      "No punctuation: terrible quality do not recommend\n",
      "Tokenized: ['terrible', 'quality', 'do', 'not', 'recommend']\n",
      "No stopwords: ['terrible', 'quality', 'recommend']\n",
      "Original: Fast shipping and good packaging, but the product is bad.\n",
      "Lower: fast shipping and good packaging, but the product is bad.\n",
      "No punctuation: fast shipping and good packaging but the product is bad\n",
      "Tokenized: ['fast', 'shipping', 'and', 'good', 'packaging', 'but', 'the', 'product', 'is', 'bad']\n",
      "No stopwords: ['fast', 'shipping', 'good', 'packaging', 'product', 'bad']\n",
      "Original: The color is not the same as shown in the picture.\n",
      "Lower: the color is not the same as shown in the picture.\n",
      "No punctuation: the color is not the same as shown in the picture\n",
      "Tokenized: ['the', 'color', 'is', 'not', 'the', 'same', 'as', 'shown', 'in', 'the', 'picture']\n",
      "No stopwords: ['color', 'shown', 'picture']\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Apply Preprocessing\n",
    "df['cleaned'] = df['Text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7482ccd2-ad1f-45f8-97f7-9b092120e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8a: TF-IDF Matrix Shape -> (6, 24)\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['cleaned'])\n",
    "print(\"8a: TF-IDF Matrix Shape ->\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c6f6a7b-5e19-4dac-a1b7-add654e78de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to preprocess input query just like reviews\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Step 9a to 9e: Retrieval function\n",
    "def retrieve_top_k_reviews(query, k=3):\n",
    "    cleaned_query = preprocess_text(query)\n",
    "    query_vector = vectorizer.transform([cleaned_query])  # Step 9b\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()  # Step 9c\n",
    "    top_k_indices = similarities.argsort()[-k:][::-1]  # Step 9d\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"\\nTop matching reviews:\\n\")\n",
    "    for idx in top_k_indices:\n",
    "        print(f\"Original Review: {df.iloc[idx]['Text']}\")\n",
    "        print(f\"Cleaned Review: {df.iloc[idx]['cleaned']}\")\n",
    "        print(f\"Similarity Score: {similarities[idx]:.4f}\")\n",
    "        print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b675f5e-a5df-4f44-a690-b5558e5182a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
